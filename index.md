Knowledgeeembedding
=====

![Knowledge Embedding](/figures/logo.png)

## News and updates

* Sept. 26, 2022: Initial webpage rendering!
* Sept. 28, 2022: Update the documentÔºÅ

## Overview

Welcome to the Knowledge Embedding Dataset project!

### What is Knowledge Embedding Dataset

....


## Research Team

....

## Citations and publications

....

## References

### Knowledge Injection and Visual concept extraction

* Hu Z, Ma X, Liu Z, et al. Harnessing deep neural networks with logic rules[J]. arXiv preprint arXiv:1603.06318, 2016.   [paper](https://arxiv.org/abs/1603.06318).  [code](https://github.com/ZhitingHu/logicnn).
* Ning G, Zhang Z, He Z. Knowledge-guided deep fractal neural networks for human pose estimation[J]. IEEE Transactions on Multimedia, 2017, 20(5): 1246-1259.   [paper](https://ieeexplore.ieee.org/ielaam/6046/8340086/8064661-aam.pdf).    [code](https://github.com/Guanghan/GNet-pose).
* Shen Y, Deng Y, Yang M, et al. Knowledge-aware attentive neural network for ranking question answer pairs[C]//The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. 2018: 901-904.  [paper](https://www.researchgate.net/publication/326137147_Knowledge-aware_Attentive_Neural_Network_for_Ranking_Question_Answer_Pairs). 
* Kursuncu U, Gaur M, Sheth A. Knowledge infused learning (k-il): Towards deep incorporation of knowledge in deep learning[J]. arXiv preprint arXiv:1912.00512, 2019. [paper](https://arxiv.org/abs/1912.00512).    
* Ge Y, Xiao Y, Xu Z, et al. A peek into the reasoning of neural networks: Interpreting with structural visual concepts[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 2195-2204.   [paper](https://arxiv.org/abs/2105.00290).
* Shevchenko V, Teney D, Dick A, et al. Reasoning over vision and language: Exploring the benefits of supplemental knowledge[J]. arXiv preprint arXiv:2101.06013, 2021. [paper](https://arxiv.org/abs/2101.06013)
* Sharifzadeh S, Baharlou S M, Tresp V. Classification by attention: Scene graph classification with prior knowledge[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 35(6): 5025-5033. [paper](https://ojs.aaai.org/index.php/AAAI/article/view/16636)

### Knowledge Guide

* Marino K, Salakhutdinov R, Gupta A. The more you know: Using knowledge graphs for image classification[J]. arXiv preprint arXiv:1612.04844, 2016.   [paper](https://arxiv.org/abs/1612.04844). 
* Marino K, Salakhutdinov R, Gupta A. The more you know: Using knowledge graphs for image classification[J]. arXiv preprint arXiv:1612.04844, 2016.    [paper](https://arxiv.org/abs/1612.04844).
* Fang Y, Kuan K, Lin J, et al. Object detection meets knowledge graphs[C]. International Joint Conferences on Artificial Intelligence, 2017.    [paper](https://ink.library.smu.edu.sg/sis_research/4067/).
* Von Rueden L, Mayer S, Beckh K, et al. Informed Machine Learning--A Taxonomy and Survey of Integrating Knowledge into Learning Systems[J]. arXiv preprint arXiv:1903.12394, 2019.   [paper](https://arxiv.org/abs/1903.12394).    [code](https://github.com/tvhahn/weibull-knowledge-informed-ml)
* Kursuncu U, Gaur M, Sheth A. Knowledge infused learning (k-il): Towards deep incorporation of knowledge in deep learning[J]. arXiv preprint arXiv:1912.00512, 2019. [paper](https://arxiv.org/abs/1912.00512).   
* Sheth A, Gaur M, Kursuncu U, et al. Shades of knowledge-infused learning for enhancing deep learning[J]. IEEE Internet Computing, 2019, 23(6): 54-63.  [paper](https://ieeexplore.ieee.org/abstract/document/8970629).
* Chen T, Lin L, Hui X, et al. Knowledge-guided multi-label few-shot learning for general image recognition[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020.   [paper](https://ieeexplore.ieee.org/abstract/document/9207855/)
* Zareian A, Karaman S, Chang S F. Bridging knowledge graphs to generate scene graphs[C]//European conference on computer vision. Springer, Cham, 2020: 606-623.    [paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123680596.pdf).    [code]( https://github.com/alirezazareian/gbnet)
* Ge Y, Xiao Y, Xu Z, et al. A peek into the reasoning of neural networks: Interpreting with structural visual concepts[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 2195-2204. [paper](https://arxiv.org/abs/2105.00290).  
* Yu F, Tang J, Yin W, et al. Ernie-vil: Knowledge enhanced vision-language representations through scene graphs[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 35(4): 3208-3216. [paper](https://ojs.aaai.org/index.php/AAAI/article/view/16431).    
* Shevchenko V, Teney D, Dick A, et al. Reasoning over vision and language: Exploring the benefits of supplemental knowledge[J]. arXiv preprint arXiv:2101.06013, 2021.   [paper](https://arxiv.org/abs/2101.06013).  
* Yu F, Tang J, Yin W, et al. Ernie-vil: Knowledge enhanced vision-language representations through scene graphs[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 35(4): 3208-3216. [paper](https://ojs.aaai.org/index.php/AAAI/article/view/16431).
* Sharifzadeh S, Baharlou S M, Tresp V. Classification by attention: Scene graph classification with prior knowledge[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 35(6): 5025-5033. [paper](https://ojs.aaai.org/index.php/AAAI/article/view/16636)
* Dash, Tirtharaj, et al. "A review of some techniques for inclusion of domain-knowledge into deep neural networks." Scientific Reports 12.1 (2022): 1-15.  [paper](https://europepmc.org/backend/ptpmcrender.fcgi?accid=PMC8776800&blobtype=pdf).

### KG-HOI

* Li Y L, Zhou S, Huang X, et al. Transferable interactiveness knowledge for human-object interaction detection[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: 3585-3594. [paper](https://arxiv.org/pdf/1811.08264.pdf).  [code](https://github.com/DirtyHarryLYL/Transferable-Interactiveness-Network).
* Xu B, Wong Y, Li J, et al. Learning to detect human-object interactions with knowledge[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019.   [paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8953301)
* Zhuo T, Cheng Z, Zhang P, et al. Explainable video action reasoning via prior knowledge and state transitions[C]//Proceedings of the 27th acm international conference on multimedia. 2019: 521-529.  [paper](https://arxiv.org/pdf/1908.10700.pdf).  [code](https://github.com/visiontao/evar).
* Kim D J, Sun X, Choi J, et al. Detecting human-object interactions with action co-occurrence priors[C]//European Conference on Computer Vision. Springer, Cham, 2020: 718-736.    [paper](https://arxiv.org/pdf/2007.08728.pdf).  [code](https://github.com/Dong-JinKim/ActionCooccurrencePriors/).
* Kim D, Lee G, Jeong J, et al. Tell me what they're holding: Weakly-supervised object detection with transferable knowledge from human-object interaction[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(07): 11246-11253.    [paper](https://arxiv.org/pdf/1911.08141.pdf).
* Lin X, Zou Q, Xu X, et al. Effects of Motion-Relevant Knowledge From Unlabeled Video to Human-Object Interaction Detection[J]. IEEE Transactions on Neural Networks and Learning Systems, 2021.   [paper](https://ieeexplore.ieee.org/abstract/document/9646232/).
* Hou Z, Yu B, Qiao Y, et al. Affordance transfer learning for human-object interaction detection[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 495-504. [paper](https://arxiv.org/pdf/2104.02867v1.pdf).    [code](https://github.com/zhihou7/HOI-CL).
* Morais R, Le V, Venkatesh S, et al. Learning asynchronous and sparse human-object interaction in videos[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 16041-16050. [paper](https://arxiv.org/pdf/2103.02758.pdf).  [code](https://github.com/RomeroBarata/human_object_interaction).
* Chen J, Wu X, Hu Y, et al. Spatial-temporal causal inference for partial image-to-video adaptation[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 35(2): 1027-1035. [paper](https://wuxinxiao.github.io/assets/papers/2021/Spatial-temporal_Causal_Inference.pdf).  [code](https://github.com/ChenJinBIT/HPDA)
* Yang L, Li K, Zhan X, et al. OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object Interaction[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 20953-20962.   [paper](https://arxiv.org/pdf/2203.15709.pdf).  [code](https://github.com/lixiny/oakink)
* Liu R, Zheng G, Gupta S, et al. Knowledge infused decoding[J]. arXiv preprint arXiv:2204.03084, 2022. [paper](https://arxiv.org/abs/2204.03084).  [code](https://github.com/microsoft/kid
)
* Hua H, Li D, Li R, et al. Towards Explainable Action Recognition by Salient Qualitative Spatial Object Relation Chains[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2022, 36(5): 5710-5718. [paper](https://www.aaai.org/AAAI22Papers/AAAI-4289.HuaH.pdf).

### MOE 

* Valada A, Dhall A, Burgard W. Convoluted mixture of deep experts for robust semantic segmentation[C]//IEEE/RSJ International conference on intelligent robots and systems (IROS) workshop, state estimation and terrain perception for all terrain mobile robots. 2016, 2.  [paper](http://www.lifelong-navigation.eu/files/valada16irosws.pdf).  [code](https://github.com/DeepSceneSeg/CMoDE).
* Fu H, Gong M, Wang C, et al. MoE-SPNet: A mixture-of-experts scene parsing network[J]. Pattern Recognition, 2018, 84:226-236. [paper](https://arxiv.org/pdf/1806.07049.pdf).
* Wang X, Yu F, Dunlap L, et al. Deep mixture of experts via shallow embedding[C]//Uncertainty in artificial intelligence. PMLR, 2020: 552-562. [paper](https://arxiv.org/pdf/1806.01531v1.pdf).
* Minaee S, Boykov Y Y, Porikli F, et al. Image segmentation using deep learning: A survey[J]. IEEE transactions on pattern analysis and machine intelligence, 2021.    [paper](https://arxiv.org/pdf/2001.05566.pdf).
* Riquelme C, Puigcerver J, Mustafa B, et al. Scaling vision with sparse mixture of experts[J]. Advances in Neural Information Processing Systems, 2021, 34: 8583-8595. [paper](https://arxiv.org/pdf/2106.05974.pdf).  [code](https://github.com/google-research/vmoe).
* Fedus W, Dean J, Zoph B. A review of sparse expert models in deep learning[J]. arXiv preprint arXiv:2209.01667, 2022. [paper](https://arxiv.org/pdf/2209.01667.pdf).  [code](https://github.com/AmrElsersy/PointPainting)
* Pavlitskaya S, Hubschneider C, Struppek L, et al. Balancing Expert Utilization in Mixture-of-Experts Layers Embedded in CNNs[J]. arXiv preprint arXiv:2204.10598, 2022.   [paper](https://arxiv.org/pdf/2204.10598.pdf)
* Fingscheidt T, Gottschalk H, Houben S. Deep Neural Networks and Data for Automated Driving: Robustness, Uncertainty Quantification, and Insights Towards Safety[J]. 2022. [paper](https://library.oapen.org/handle/20.500.12657/57375)
* Ou Y, Yuan Y, Huang X, et al. Patcher: Patch Transformers with Mixture of Experts for Precise Medical Image Segmentation[J]. arXiv preprint arXiv:2206.01741
, 2022. [paper](https://arxiv.org/pdf/2206.01741.pdf).  [code](https://github.com/YanglanOu/patcher).
## Sponsors

...

## Copyright && Maintainer

Copyright (C) 2022 ETVP

Corresponding: Liang Zhang <<liangzhang@xidian.edu.cn>>

Maintainers: Zhuo Liang 