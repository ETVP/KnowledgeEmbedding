Knowledgeeembedding
=====

![Knowledge Embedding](/figures/logo.png)

## News and updates

* Sept. 28, 2022: Update the documentÔºÅ

## Overview

Welcome to the Knowledge Embedding Dataset project!

### What is Knowledge Embedding Dataset

....


## Research Team

....

## Citations and publications

....

## References

* Zhu X, Li Z, Wang X, et al. Multi-Modal Knowledge Graph Construction and Application: A Survey[J]. arXiv preprint arXiv:[2202.05786](https://arxiv.org/abs/2202.05786), 2022.
* Marino K, Salakhutdinov R, Gupta A. The more you know: Using knowledge graphs for image classification[J]. arXiv preprint arXiv:[1612.04844](https://arxiv.org/abs/1612.04844), 2016.
* Chen T, Lin L, Hui X, et al. Knowledge-guided multi-label few-shot learning for general image recognition[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, [2020](https://ieeexplore.ieee.org/abstract/document/9207855/).
* Zareian A, Karaman S, Chang S F. Bridging knowledge graphs to generate scene graphs[C]//European conference on computer vision. Springer, Cham, [2020: 606-623](https://linkspringer.53yu.com/chapter/10.1007/978-3-030-58592-1_36).
* Ge Y, Xiao Y, Xu Z, et al. A peek into the reasoning of neural networks: Interpreting with structural visual concepts[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. [2021: 2195-2204](https://openaccess.thecvf.com/content/CVPR2021/html/Ge_A_Peek_Into_the_Reasoning_of_Neural_Networks_Interpreting_With_CVPR_2021_paper.html).
* Yu F, Tang J, Yin W, et al. Ernie-vil: Knowledge enhanced vision-language representations through scene graphs[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, [35(4): 3208-3216](https://ojs.aaai.org/index.php/AAAI/article/view/16431).
* Von Rueden L, Mayer S, Beckh K, et al. Informed Machine Learning--A Taxonomy and Survey of Integrating Knowledge into Learning Systems[J]. arXiv preprint arXiv:[1903.12394](https://arxiv.org/abs/1903.12394), 2019.
* Sharifzadeh S, Baharlou S M, Tresp V. Classification by attention: Scene graph classification with prior knowledge[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 35(6): [5025-5033](https://ojs.aaai.org/index.php/AAAI/article/view/16636).
* Dash, Tirtharaj, et al. "A review of some techniques for inclusion of domain-knowledge into deep neural networks." Scientific Reports 12.1 (2022): [1-15](https://wwwnature.53yu.com/).
* Yu F, Tang J, Yin W, et al. Ernie-vil: Knowledge enhanced vision-language representations through scene graphs[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 35(4): [3208-3216](https://ojs.aaai.org/index.php/AAAI/article/view/16431).
* Marino K, Salakhutdinov R, Gupta A. The more you know: Using knowledge graphs for image classification[J]. arXiv preprint arXiv:[1612.04844](https://arxiv.org/abs/1612.04844), 2016.
* Kursuncu U, Gaur M, Sheth A. Knowledge infused learning (k-il): Towards deep incorporation of knowledge in deep learning[J]. arXiv preprint arXiv:[1912.00512](https://arxiv.org/abs/1912.00512), 2019.
* Fang Y, Kuan K, Lin J, et al. Object detection meets knowledge graphs[C]. International Joint Conferences on Artificial Intelligence, [2017](https://ink.library.smu.edu.sg/sis_research/4067/).
* Shevchenko V, Teney D, Dick A, et al. Reasoning over vision and language: Exploring the benefits of supplemental knowledge[J]. arXiv preprint arXiv:[2101.06013](https://arxiv.org/abs/2101.06013), 2021.
* Sheth A, Gaur M, Kursuncu U, et al. Shades of knowledge-infused learning for enhancing deep learning[J]. IEEE Internet Computing, 2019, 23(6): [54-63](https://ieeexplore.ieee.org/abstract/document/8970629).
* Shen Y, Deng Y, Yang M, et al. Knowledge-aware attentive neural network for ranking question answer pairs[C]//The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval. 2018: [901-904](https://dl.acm.org/doi/abs/10.1145/3209978.3210081).
* Hu Z, Ma X, Liu Z, et al. Harnessing deep neural networks with logic rules[J]. arXiv preprint arXiv:[1603.06318](https://arxiv.org/abs/1603.06318), 2016.
* Ning G, Zhang Z, He Z. Knowledge-guided deep fractal neural networks for human pose estimation[J]. IEEE Transactions on Multimedia, 2017, 20(5): [1246-1259](https://ieeexplore.ieee.org/abstract/document/8064661/).
* Li Y L, Zhou S, Huang X, et al. Transferable interactiveness knowledge for human-object interaction detection[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2019: [3585-3594](https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Transferable_Interactiveness_Knowledge_for_Human-Object_Interaction_Detection_CVPR_2019_paper.html).
* Xu B, Wong Y, Li J, et al. Learning to detect human-object interactions with knowledge[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. [2019](https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Learning_to_Detect_Human-Object_Interactions_With_Knowledge_CVPR_2019_paper.html).
* Lin X, Zou Q, Xu X, et al. Effects of Motion-Relevant Knowledge From Unlabeled Video to Human-Object Interaction Detection[J]. IEEE Transactions on Neural Networks and Learning Systems, [2021](https://ieeexplore.ieee.org/abstract/document/9646232/).
* Kim D, Lee G, Jeong J, et al. Tell me what they're holding: Weakly-supervised object detection with transferable knowledge from human-object interaction[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2020, 34(07): [11246-11253](https://ojs.aaai.org/index.php/AAAI/article/view/6784).
* Yang L, Li K, Zhan X, et al. OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object Interaction[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: [20953-20962](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_OakInk_A_Large-Scale_Knowledge_Repository_for_Understanding_Hand-Object_Interaction_CVPR_2022_paper.html).
* Hou Z, Yu B, Qiao Y, et al. Affordance transfer learning for human-object interaction detection[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: [495-504](https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Affordance_Transfer_Learning_for_Human-Object_Interaction_Detection_CVPR_2021_paper.html).
* Morais R, Le V, Venkatesh S, et al. Learning asynchronous and sparse human-object interaction in videos[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: [16041-16050](https://openaccess.thecvf.com/content/CVPR2021/html/Morais_Learning_Asynchronous_and_Sparse_Human-Object_Interaction_in_Videos_CVPR_2021_paper.html).
* Liu R, Zheng G, Gupta S, et al. Knowledge infused decoding[J]. arXiv preprint arXiv:[2204.03084](https://arxiv.org/abs/2204.03084), 2022.
* Zhuo T, Cheng Z, Zhang P, et al. Explainable video action reasoning via prior knowledge and state transitions[C]//Proceedings of the 27th acm international conference on multimedia. 2019: [521-529]().
* Hua H, Li D, Li R, et al. Towards Explainable Action Recognition by Salient Qualitative Spatial Object Relation Chains[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2022, 36(5): [5710-5718](https://ojs.aaai.org/index.php/AAAI/article/view/20513).
* Chen J, Wu X, Hu Y, et al. Spatial-temporal causal inference for partial image-to-video adaptation[C]//Proceedings of the AAAI Conference on Artificial Intelligence. 2021, 35(2): [1027-1035](https://ojs.aaai.org/index.php/AAAI/article/view/16187).
* Kim D J, Sun X, Choi J, et al. Detecting human-object interactions with action co-occurrence priors[C]//European Conference on Computer Vision. Springer, Cham, 2020: [718-736](https://linkspringer.53yu.com/chapter/10.1007/978-3-030-58589-1_43).

## Sponsors

...

## Copyright && Maintainer

Copyright (C) 2022 ETVP

Corresponding: Liang Zhang <<liangzhang@xidian.edu.cn>>

Maintainers: Zhuo Liang 